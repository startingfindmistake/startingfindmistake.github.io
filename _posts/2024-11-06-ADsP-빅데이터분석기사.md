---
layout: post
title: "ADsP 빅데이터분석기사"
categories: BigData
excerpt_image: /assets/images/i_posts/ADsP.jpg
author: "YeongHo-Jung"
meta: "Springfield"
tags: [github, gitClone]
---
# 1과목 데이터의 이해

## 01 데이터의 정의
* 데이터는 객관적 사실이라는 존재적 특성과 동시에 추론, 예측, 전망, 추정을 위한 근거로 기능하는 당위적 특성을 의미한다.
* 데이터는 다른 객체와의 상호관계일 때 가치를 갖는다는 의미이다.

### 출제유형
   * "객관적 사실로서 개별 데이터는 중요하지 않음을 의미한다." 객관형 오답 문제

---

## 02 데이터의 유형
1. 정성적 데이터(Qualitative data)
* 언어, 문자 등 형태와 형식이 정해져 있지 않음
* 비정형 데이터 형태로 저장, 분석에 시간과 비용이 필요
* 숫자나 금액으로 환산할 수 없는 것
* ex) 설문조사의 주관식 응답, 트위터, 페이스북 등이 해당

### 출제유형
* 주관식 설문조사가 정성적 데이터는 맞지만, 문제에서 설문조사는 비정형 데이터라고 한다면 틀린 보기
* 객관식 설문 문항이 수치 처리가 가능하면 정량적 데이터도 가능

2. 정량적 데이터(quantitative data)
* 수치, 기호, 도형으로 표시
* 데이터양이 증가하더라도 저장, 분석이 용이
* 숫자나 금액으로 환산 가능한 것
* ex) 온도, 풍속, 강수량 등이 해당

### 출제유형
* 정량적 vs 정량적 데이터 구분 문제

---

## 03 암묵지 vs 형식지
* 데이터는 지식경영의 핵심 이슈인 암묵지와 형식지의 상호 작용에 있어 중요한 역활을 함
1. 암묵지: 학습과 체험을 통해 개인에게 습득되어 있지만, 겉으로 드러나지 않은 지식, 시행착오와 오랜 경험을 통해 개인에게 습득된 무형의 지식 -> 개인에게 체화되어 있으므로 외부에 표출되어 공유가 어려움.
2. 형식지: 교과서, 메뉴얼, 비디오, DB와 같이 형상화된 지식을 의미, 유형의 대상이 있어서 지식의 전달과 공유가 쉬움

### 출제유형
* 형식지와 암묵지 개념과 사례 구분

## 04 암묵지와 형식지의 상호 작용
* 공통화(Socialization) : 암묵지 지식 노하우를 다른 사람에게 알려줌
* 표준화(Externalization) : 암묵지 지식 노하우를 책, 교본 형식으로 전환함
* 연결화(Combination) : 책, 교본에 자신이 알고 있는 새로운 지식을 추가함
* 내면화(Internalization) : 만들어진 책, 교본을 보고 다른 직원의 암묵적 지식을 습득함

### 출제유형
* 상호작용의 4가지 개념

---

## 05 데이터와 정보의 관계
* 데이터의 당위적 특성인 근거의 기능에 주목하여 데이터와 정보의 관계를 살펴볼 때 DIKW 정의가 필요하다
* DIKW 피라미드(Data -> Information -> Knowledge -> Wisdom) 데이터, 정보, 지식을 통해 최종적으로 지혜를 얻어내는 과정
1. Data : 존재 형식을 불문하고, 타 데이터와의 상관관계가 없는 가공하지 전의 순수한 수치나 기호</br>
ex) 연필 가격: A 마트 100원, B 마트는 200원
2. Information : 데이터의 가공 및 상관관계 간 이해를 통해 패턴을 인식하고 의미 부여</br>
ex) A 마트의 연필 가격이 더 싸다
3. Knowledge : 상호 연결된 정보 패턴을 이해하여 이를 토대로 예측한 결과물</br>
ex) 상대적으로 저렴한 A 마트에서 연필을 사야겠다.
4.Wisdom : 근본 원리에 대한 깊은 이해를 바탕으로 도출되는 아이디어</br>
ex) A 마트의 다른 상품들도 B 마트보다 저렴할 것으로 판단


### 출제유형
* DIKW 개념 구분과 사례

---

## 06 데이터베이스 정의
- 동시에 복수의 적용 업무를 지원할 수 있도록 복수의 이용자 요구에 대응해서 받아들이고 저장, 공급하기 위하여 일정한 구조에 따라 발생된 데이터의 집합
- 데이터베이스 관리시스템(DBMS: DataBase Management System)은 데이터베이스를 조작하는 별도의 소프트웨어로, DBMS를 통해 데이터베이스를 관리하여 응용 프로그램들이 데이터베이스를 공유하고 사용할 수 있는 환경을 제공.
- DBMS는 데이터베이스를 구축하는 툴을 제공하고, 효율적으로 데이터를 검색하고 저장하는 기능을 제공한다. 또한 응용 프로그램들이 데이터베이스에 접근할 수 있는 인터페이스를 제공하고, 장애에 대한 복구 기능, 사용자 권한에 따른 보안 유지 기능 등을 제공한다.

### 출제 유형
- 데이터베이스와 데이터베이스 관리시스템 개념 구분

---

## 07 DBMS의 발전 과정
1. **1세대**: 네트워크형 DBMS, 계층형 DBMS
   - 복잡하고 변경이 어려움
2. **2세대**: 관계형(Relation) DBMS
   - 데이터베이스를 테이블 형태 구성
   - ex) 오라클(유료), 액세스, MySQL(무료)
3. **3세대**: 객체 지향(Objected) DBMS
   - 멀티미디어 데이터를 확산으로 관계형 데이터 모델을 표현하기 어려움.   
   같은 행위를 갖는 객체는 한 크래스에 속하며, 클래스 연산을 나타내기 위해 메소드 함수를 정의함   
   **객체 관계형 모델(ORDBMS)**
   - 기존의 관계형 모델에 객체 지향형 모델의 장점 선별하여 관계형 모델에 통합한 새로운 개념의 데이터 모델
4. **4세대**: NoSQL DBMS
   - 데이터 구조를 미리 정해두지 않기 때문에 비정형 데이터를 저장하고 처리함

| 구분                | SQL 데이터베이스                          | NoSQL 데이터베이스                        |
|---------------------|-------------------------------------------|-------------------------------------------|
| **데이터 모델**     | 관계형 모델로 데이터를 형태화된 구성된 테이블 정규화 | 가상 문서, 그래프도 가능하나 고유 확장이 적합한 데이터 모델을 제공함 |
| **최적의 워크로드** | 관계형 데이터베이스는 일반적으로 뛰어난 온라인(TLP) 애플리케이션을 위해 최적화된 환경과 분석 프로세스(OLAP)에 적합함 | NoSQL 데이터베이스는 낮은 지연 시간에서의 분할/레이아웃을 포함하여 비정형 데이터를 대량 패턴에 맞도록 설계됨. NoSQL 또한 단일 데이터 구조에 비정형 데이터와 분석을 위해 설계됨 |

### 출제 유형
- SQL과 NoSQL 특징

---

## 08 관계형 데이터베이스 관리시스템(RDBMS) vs 객체 지향 데이터베이스 관리시스템(ODBMS)의 특징 구분

| 구분             | 관계형 데이터베이스(RDBMS)    | 객체지향 데이터베이스(ODBMS)  |
|------------------|-------------------------------|-------------------------------|
| **데이터 타입**  | 문자, 숫자, 날짜의 단순한 데이터 타입만 지원 | 사용자 정의 타입 및 범용 복합형 데이터 타입 지원 |
| **주된 장점**    | 오랜 기간에 걸쳐 검증된 시스템 안정성과 대규모 정보 처리 성능 | 복잡한 정보 구조의 모델링 가능 |
| **주된 단점**    | 형태 변화된 정보 처리 가능. 복잡한 정보 구조의 모델링 어려움 | 기본적인 데이터베이스 관리 기능에 비해 정보 및 성능의 효율성 미비 |

### 출제 유형
- RDBMS와 ODBMS 차이점

---

## 09 데이터 유형 분류

| 데이터 유형       | 특징                                                                                  | 데이터 종류                          |
|-------------------|---------------------------------------------------------------------------------------|--------------------------------------|
| **정형 데이터**   | - RDBMS의 고정된 필드에 저장<br>- 데이터 스키마 지원                                   | - RDB<br>- 스프레드시트              |
| **반정형 데이터** | - 데이터 속성인 메타데이터를 가지며, 일반적으로 스토리지에 저장되는 데이터 파일        | - HTML<br>- JSON<br>- 웹 문서<br>- 센서 데이터 |
| **비정형 데이터** | - 형태가 구조적 복잡한 이미지, 동영상 같은 멀티미디어 데이터                           | - 소셜 데이터<br>- 문서 이미지<br>- 오디오, 비디오 |


---

### 출제 유형
- 데이터의 유형 특징 구분, 종류

---

## 10 스키마의 인스턴스
* 스키마(Schema): 구조를 만드는 것   
구체적으로 데이터베이스의 구조와 제약조건을 기술

| 상품 아이디 | 카테고리 | 상품명 | 상품가격 | 상품재고 |
|----------|--------|------|--------|--------|
| 문자형     | 숫자형  | 문자형 | 숫자형   | 숫자형   |

* 인스턴스(Instance): 특정 시점의 데이터베이스 내용

---

## 11 데이터베이스 설계 순서
1. 요구조건 분석
2. 개념적 설계(E - R 모델)
3. 논리적 설계(테이블 설계)
4. 물리적 설계(데이터 구조화)

### 출제 유형
* 데이터베이스 설계순서

## 12 데이터베이스의 특징
1. 통합된 데이터(Integrated data)
2. 저장된 데이터(Stored data)
3. 공용 데이터(Shared data)
4. 변화되는 데이터(Changed data)

### 출제 유형
* 데이터베이스 특징과 데이터웨어하우스 특징의 차이점

## 13 데이터베이스 특성
1. 정보의 축적 및 전달 측면
2. 정보이용 측면
3. 정보관리 측면
4. 정보기술 발전 측면
5. 경제, 산업적 측면

### 출제 유형
* 데이터베이스 특성

## 14 OLTP vs OLAP
1. **OLTP(on-Line Transaction Processing)**:   
네트워크상의 여러 이용자가 실시간으로 데이터베이스의 데이터를 갱신하거나 조회하는 등의 단위작업을 처리하는 방식   
ex) 은행에서 수많은 입출금 등이 일어날 때   
2. **OLAP(On-Line Analytic Processing)**:
정보 위주의 처리분석을 의미한다. 의사결정에 활용할 수 있는 정보를 얻을 수 있게 해주는 기술
ex) 판매 추이, 구매성향 파악, 재무회계 분석 등을 프로세싱하는 것

### 출제 유형
* OLTP와 OLAP의 차이

---

## 15 데이터웨어하우스 vs 데이터 마트
* 데이터 마트는 데이터웨어하우스 환경에서 정의된 접근 계층으로, 데이터웨어하우스에서 데이터를 꺼내 사용자에게 제공하는 역활을 함
* 데이터 마트는 데이터웨어하우스의 부분이며, 특정한 조직, 혹은 팀에서 사용하는 것을 목적으로 함

### 출제 유형
* 데이터마트와 데이터웨어하우스의 개념 구분

---

## 16 데이터웨어하우스 특징
1. 데이터의 주제지향성
2. 데이터의 통합성
3. 데이터의 시계열성
4. 데이터의 비휘발성

### 출제 유형
* 데이터웨어하우스와 데이터베이스 특징 구분 문제

---

## 17 CRM와 SCM
2000년대 들어서면서 기업 DB 구축의 화두 CRM / SCM   
1. **CRW**: 선별된 고객으로부터 수익을 창출하고 장기적인 고객 관계를 가능케 함으로써 보다 높은 이익을 창출할 수 있는 솔루션
2. **SCM**: 제조, 물류, 유통업체 등 유통 공급망에 참여하는 모든  업체가 협력을 바탕으로 정보기술을 활용, 재고를 최적화하기 위한 솔루션   
-> SCM과 CRM은 연동되기 때문에 상호 밀접한 관계, 오늘날 CRM은 기존의 목적은 변화되지 않고 방법론에서만 변화하고 있음

### 출제 유형
* CRM과 SCM의 개념

----

## 18 실시간 기업(RTE : Real-Time Enterprise)
가트너는 RTE를 '최신 정보를 사용해 자사의 핵심 비즈니스 프로세스들의 관리와 실행 과정에서 생기는 지연 사태를 지속해서 제거함으로써 경쟁하는 기업'으로 정의

---

## 19 ERP와 BI
1. **ERP**: 제조업을 포함한 다양한 비즈니스 분야에서 생산, 구매, 재고, 주문, 공급자와의 거래, 고객 서비스 제공 등 주요 프로세스 관리를 돕는 여러 모듈로 구성된 통합 솔루션
2. **BI(Business intelligence)**: 데이터 기반 의사결정을 지원하기 위한 리포트 중심의 도구
3. **BA(Business Analytics)**: 는 소프트웨어로 데이터를 분석해 미래를 예측하거나(예측 분석), 특정 접근법을 적용했을 때 발생할 수 있는 일을 내다보는(처방적 분석) 기술의 도움을 받는 과정이다. 그래서 BA는 '고급분석(advanced analytics)'이라고도 불린다.   
-> 의사결정을 위한 통계적이고 수학적인 분석에 초점

### 출제 유형
* ERP 정의, BI와 BA 개념 구분

---

## 20 기타 기업내부 데이터베이스 솔루션
1. EAI는 Enterprise Architecture Integration의 약자로 기업 애플리케이션 통합을 의미, 기업 내의 ERP(전사적자원관리), CRM(고객관계관리), SCM(공그망계획) 시스템이나 인트라넷 등의 시스템 간에 상호 연동이 가능하도록 통합하는 솔루션
2. EDW(Enterprise Data Warehouse)는 기존 DW(DataWarehouse)를 전사적으로 확장한 모델인 동시에 BPR과 CRM, BSC 같은 다양한 분석 애플리케이션들을 위한 원천이 됨. 따라서 EDW를 구축하는 것은 단순히 정보를 빠르게 전달하는 대형 시스템을 도입한다는 의미가 아니라 기업 리소스의 유기적 통합, 다원화된 관리체계 정비, 데이터의 중복 방지 등을 위해 시스템을 재설계하는 것
3. 블록체인(Blockchain): 데이터분산 처리 기술. 네트워크 참여하는 모든 사용자가 모든 거래내용 등의 데이터를 분산, 저장하는 기숭르 말함. 블록들을 체인 형태로 묶는 형태이기 때문에 브록체인이라는 명칭이 생겨남. 기존 거래 방식에서 데이터를 위-변조하기 위해는 은행의 중앙 서버를 공격하면 가능했으나 최근 은행 전산망 해킹 사건이 발생했으나 블록체인일때 사실상 해킹이 불가능함

### 출제 유형
* 각 솔루션의 정의

---

## 21 빅데이터(Big Data)특징
1. Volume(데이터의 크기): 생성되는 모든 데이터를 수집
2. Variety(데이텅의 다양성): 정형화된 데이터를 넘어 텍스트, 오디오, 비디오 등 모든 유형의 데이털르 분석 대상으로 한다.
3. Velocity(데이터의 속도): 두 가지 관점의 속도를 의미함

### 출제 유형
* 3V 정의

---

## 22 빅데이터 등장하게 된 결정적 요인
1. 기술변화
* 클라우드 컴퓨팅 활용
* 새로운 데이터 처리, 저장, 분석 기술 및 아키텍쳐
2. 인재-조직변화
* 데이터 중심 조직/데이터 사이언티스트 요구

### 출제 유형
* "클라우드 컴퓨팅과 분산처리 기술이 빅데이터가 등장하게 된 결정적 요인이다." 객관형 문제로 출제

---

## 23 빅데이터 출현 배경
빅데이터 현상은 없었던 것이 새로 등장한 것이 아니라 기존의 데이터, 처리방식, 다루는 사람과 조직 차원에서 일어나는 '변화'를 의미함
1. 산업계 - 양질 전환 법칙
2. 학계 - 빅데이털르 다루는 현상이 증가
3. 관련 기술발전 - 디지털화, 저장기술발전, 인터넷과 모바일 시대 진전에 따른 클라우드 컴퓨팅


### 출제 유형
* 빅데이터 출현배경에 관한 문제

---

## 24 빅데이터 기능
1. 빅데이터는 산업혁명의 석탄, 철에 비유된다.
2. 빅데이터는 원유에 비유된다.
3. 빅데이터는 렌즈에 비유된다.   
ex) ngram viewer, 현미경이 있다
4. 빅데이터는 플랫폼에 비유된다.   
플랫폼이란 다양한 차원에서 활용되는 개념이지만, 비즈니스 측면에서는 일반적으로 '공동 활용의 목적으로 구축된 유무형의 구조물'을 의미한다.
ex) 페이스북, OS 여기에 해당한다.

### 출제 유형
* 빅데이터의 렌즈와 플랫폼의 기능과 사례

---

## 25 빅데이터가 만들어 내는 본질적 변화
1. 정보의 사전처리에서 사후처리 시대로
2. 표본조사에서 전수조사로
3. 질보다 양으로 - 구글의 자동번역, 결정의 계수
4. 인과관계에서 상관관계로

### 출제 유형
* 빅데이터가 만든 본질적인 변화 출제

---

## 26 빅데이터의 가치 산정이 어려운 이유
1. 데이터 활용 방식   
데이터의 재사용, 재조합(Mashup), 다목적용 데이터 개발 등이 일반화되면서 특정 데이터를 언제, 어디서, 누가 활용할지 알 수 없다.   
   * 재사용 사례 - 구글 검색결과를 저장 후 재사용한다.
   * 다목적용 사례 - 전기자동차의 배터리 충전시간 & 주유소 위치
      * CCTV(절도범 & 구매정보)
   * 재조합 사례 - 휴대전화 전자파가 뇌종양 관계
2. 데이터가 기존에 없던 가치 창출을 한다.   
ex)아마존 킨들 전자책 읽기 관련 데이터 분석을 하면 독서 패턴을 알 수 있다.
   * 페이스북 소셜커머스 그래프
3. 분석 기술의 발달이 데이터에 가치에 영향을 준다.
* 기존에는 가치가 없는 데이터도 새로운 분석기법으로 가치를 만든다.   
ex) SNS 비정형 데이터 이용한 텍스트마이닝 활용

### 출제 유형
* 빅데이터 가치 산정이 어려운 이유와 사례

---

## 27 빅데이터 활용 대표 사례
1. 기업 활용
   * 구글 검색(로그 데이터 활용 기존 페이지랭크 개선)
   * 월마트 구매 패턴 분석(연관규칙)
   * IMB 왓슨 인공지능 병원 진료에 활용
2. 정부 활용
   * 환경탐색(실시간 교통정보수집, 기후정보)
   * 상황분석(소셜미디어, CCTV, 통화기록)
3. 개인활용
   * 정치인의 SNA 활용
   * 가수 팬들의 청취 분석

### 출제 유형
* 빅데이터 활용 사례

---

## 28 빅데이터 활용 기법
1. **연관규칙학습(Association rule learning)**:   
어떤 변수간에 주목할 만한 상관관계가 있는지를 찾아내는 방법   
ex) 마트에서 상관관계가 높은 상품을 함께 진열(우유와 기저귀)
2. **유형 분석(Classification tree analysis)**:   
'사용자가 어떤 특성을 가진 집단에 속하는가?'와 같은 문제를 해결하고자 할 때 사용   
ex) 온라인 수강생들의 특성에 따른 분류
3. **유전 알고리즘(Genetic algorithms)**:   
'최대의 시청률을 얻으려면 어떤 프로그램을 어떤 시간대에 방송해야 하는가?'와 같은 최적화의 메커니즘을 찾아가는 방법   
ex) 연료 효율적인 차를 개발하기 위해 어떻게 원자재와 엔지니어링을 결합해야 하는가?, 응급실에서 으ㅢ사를 어떻게 배치하는 것이 가장 효율적인가?
4. **기계 학습(Machine learning**:
기존의 시청 기록을 바탕으로 시청자가 현재 보유한 영화 중에서 어떤 것을 가장 보고 싶어 할까? 와 같은 문제를 해결할 때 사용. 기계학습 알고리즘은 훈련 데이터를 기반으로 모형을 만들고 그 모형을 이용하여 예측하거나 의사결정에 활용할 수 있도록 함
ex) 넷프릭스 영화 추천 시스템
5. **회귀분석(Regression Analysis)**:
'구매자의 나이가 구매 차량의 타입에 어떤 영향을 미치는가?'와 같은 질문에 답할 때 사용한다. 분석자는 독립변수를 사용하여, 종속변수가 어떻게 변하는지를 보며 두 변수의 관계를 파악한다.
6. **감성분석(Sentiment Analysis)**:
'새로운 환불 정책에 대한 고객의 평가는 어떤가?를 알고 싶을 때 활용
ex) 소셜미디어에 나타난 의견을 바탕으로 고객이 원하는 것을 찾아낼 때 사용된다.
7. **소셜 네트워크 분석(Social network analysis)**:
영향력 있는 사람을 찾아낼 수 있으면, 고객들 간 소셜커머스 관계를 파악할 수 있음.

### 출제 유형
* 분석기법 정의와 사례

---

## 29 빅데이터 시대의 우ㅟ기 요인과 통제 방안
1. **사생활 침해**
->(위기 요인) 빅데이터 시대가 본격화되면서 우리달 둘러싼 정보 수집 센서(M2M)들의 수가 점점 늘어나고 있고, 특정 데이터가 본래 목적 외에 가공돼 2차 - 3차 적 목적으로 활용될 가능성이 증가하면서 사생활 침해를 넘어 사회 - 경제적 위협으로 변형될 수 있음

->(통제방안) 동의에서 책임으로 - 개인정보의 활용에 대한 개인이 매번 동의하는 것은 경제적으로도 매우 비 효율적이다. 따라서 사생활 침해 문제를 개인정보 제공자의 동의를 통해 해결하기보다는 개인정보 사용자 에게 책임을 지움으로써 개인정보 사용 주체가 더욱 적극적인 보호 장치를 마련하게 하는 효곽가 발생할 것으로 기대된다.(개인정보 사용자가 책임)

2. **책임 원칙의 훼손**
->(위기 요인) 빅데이터 기반분석과 예측 기술이 발전하면서 정확도가 증가한 만큼, 분석 대상이 되는 사람들은 예측 알고리즘의 희생양이 될 가능성이 증가한다. 그러나 잠재적 위험 사항에 대해서도 책임을 추궁하는 사회로 번질할 가능성이 커 민주주의 사회 원칙을 크게 훼손할 수 있다.
ex) 범죄예측 프로그램

->(통제방안) 기존의 책임원칙을 더 보강하고 강화한다.

3. **데이터의 오용**
->(위기요인)빅데이터는 일어난 일에 대한 데이터에 의존한다. 그것을 바탕으로 미래를 예측하는 것은 적지 않은 정확도를 가질 수 있지만, 항상 맞을 수는 없다.주어진 데이터에 잘못된 인사이트를 얻어 비즈니스에 직접 손실을 불러올 수 있다.

->(통제방안)데이터 알고리즘에 대한 접근권 허용 및 객관적 인증방안을 도입 필요성 제기. 이로 인해 알고리즈미스트 역활 요구.

### 출제 유형
* 위기요인과 통제방안을 연계한 문제

---

## 30. 데이터 3법이란
데이터 3법은 데이터 이용을 활성화하는 '개인정보보호법', '정보통신망 이용촉진 및 정보보호 등에 관한 법률(이하 정보통신망법)','신용정보의 이용 및 보호에 관한 법률(이하 신용정보법)'등 3가지 법률이 통칭한다.

### 출제 유형
* 데이터 3법의 종류

---

## 31 개인정보의 수집 및 수집 목적 내 이용이 가능한 경우
* 정보 주체의 동의를 받는 경우
* 법률에 특별한 규정이 있거나 법령상 의무를 준수하기 위하여 불가피한 경우
* 정보주체와의 계약의 체결 및 이행을 위하여 불가피하게 필요한 경우
* 정보주체와의 계약의 체결 및 이행을 위하여 불가피하게 필요한 경우
* 명백히 정보주체 등의 급박한 생명, 신체, 재산의 이익을 위해 필요한 경우
* (정보주체의 권리보다 우선하는)개인정보처리장의 정당한 이익 달성을 위하여 필요한 경우

### 출제 유형
* 개인정보의 수집 및 이용이 가능한 경우

---

## 32 개인정보 수집 - 이용동의 시 필수 고지 사항
1. 개인정보의 수집 - 이용 목적
2. 수집하려는 개인정보의 항목
3. 개인 정보의 보유 및 이용 기간
4. 동의를 거부할 권리가 있다는 사실 및 동의 거부에 따른 불이익이 있는 경우에는 그 불이익의 내용

### 출제 유형
* 개인정보 수집 및 이용 동의 시 필수 고지사항

---

## 33 개인정보 비식별화
1. 개인정보 : 살아 있는 개인에 관한 정보로서 성명, 주민등록번호 및 영상 등을 통하여 개인을 알아볼 수 있는 정보
2. 비식별화 : 정보의 일부 또는 전부를 삭제 또는 대체하거나 다른 정보와 쉽게 결합하지 못하도록 하여 특정 개인을 알아볼 수 없도록 하는 일련의 조치
3. 개인정보 식별요소 제거방법 및 예시

| 비식별 기술 | 제거방법 | 예시 |
|----------|--------|-----|
| 가명처리 | 식별요소를 다른 값으로 대체 | 홍길동, 35세, 서울 거주, 한국대 재학, <br> -> 임꺽정, 30대, 서울 거주, 국제대 재학 |
| 총계처리 또는 평균값 대체 | 데이터를 총합으로 표시하여 개별 데이터값을 보이지 않도록 함 | 임꺽정 180cm, 홍길동 170cm <br> -> 1-5반 학생 키 합 350cm, 평균 키 175cm |
| 데이터값 삭제 | 개인 식별을 인식할 수 있는 값 삭제 | 홍길동, 35세, 서울 거주, 한국대 졸업 <br> -> 35세, 서울거주 |
| 범주화 | 범주의 값으로 변환 | 홍길동, 35세 <br> -> 홍 씨, 30~40 세|
| 데이터 마스킹 | 개인 식별자가 보이지 않도록 처리 | 홍길동 , 35세 <br>-> 홍 * *, 35세|

### 출제 유형
* 비식별기술 개념과 예시

---

## 34 빅데이터의 활용에 필요한 3요소
1. 데이터: 모든 것의 데이터화(Datafication)
2. 기술: 진화하는 알고리즘, 인공지능
3. 인력: 데이터사이언티스트, 알고리즈미스트

### 출제 유형
* 3가지 활용 요소

---

## 빅데이터 열풍과 회의론
1. 빅데이터 분석은 데이터에서 가치, 즉 통창르 끌어내는 것이 성과를 창출하는 것이 관건<br>
-> 복잡하고 다양한 데이터를 최적화 능력이 반드시 최고의 가치를 창출하는 것은 아니고. 가치에 적합한 분석을 하는 것이 중요 포인트
2. 데이터는 크기의 이슈가 아니라, 거기에서 어떤 시각과 통찰을 얻을 수 있느냐의 문제이다. 빅데이터와 관련된 걸림돌은 '비용이 아니라 분석적 방법과 성과에 대한 이해 부족이다.
3. 대부분 성과가 높은 기업일수록 데이터 기반에 의한 의사결정을 하지만 성과가 우수한 기업들도 가치 분석적 통찰력을 갖췄다고 대답한 비율이 낮다.<br>
-> 기업의 핵심가치와 관련한 전략적 통찰력을 가져다주는 데이터 분석을 내재화하는 것은 쉬운 일이 아님을 의미한다.

### 출제 유형
* 빅데이터 성과와 관련한 객관형 보기

## 36. 일차적인 분석 vs 전략 도충르 위한 가치 기반분석
1. 일차적인 분석을 통해서도 해당 부서는 업무영역 효과를 얻을 수 있지만, 일차적인 분석은 태생적으로 업계 내부의 문제에만 초점을 두고 있음<br>
-> 전략적 인사이트 가치 기반을 위해서 인구통계학적 변화, 경제사회 트렌드, 고객 니즈의 변화 고려해야 함. 즉 업계 상황에 한정해서 바라보지 말고 더 넓은 시야에서 차별화를 고려해야 한다.
2. 데이터 분석은 대상을 모델범위 외 요인들을 판단하게 되면 분석 모델의 정확성에 위험을 동반할 수 있음에 유의

### 출제 유형
* 일차적인 분석의 한계점

---

## 37. 데이터 사이언스 vs 데이터 마이닝 vs 통계학 차이
1. 데이터 사이언스: 데이터로부터 의미 있는 정보를 추출하는 학문
2. 통계학이 정형화된 실험 데이터를 분석 대상으로 하는 것에 비해, 데이터 사이언스는 정형 또는 비정형을 막론하고 다양한 유형의 데이털르 대상으로 총체적 접근법을 사용(통계학과 차이)
3. 데이터 마이닝은 주로 분석에 초점을 두고, 데이터 사이언스는 분석뿐 아니라 이를 효과적으로 구현하고 전달하는 과정까지 모두 포괄하는 개념(데이터 마이닝 차이)
4. 결국, 데이터 사이언스란 데이터 공학, 수학, 통계학, 컴퓨터공학, 시각화, 해커의 사고방식, 해당 분야의 전문 지식을 종합한 학문으로 정의

### 출제 유형
* 데이터 사이언스 정의와 데이터 마이닝과 통계학 차이점

---

## 38 데이터 사이언스의 핵심 구성 요소
1. IT(Data Management)
2. ANalytics(분석적 영역)
3. 비즈니스 분석

### 출제 유형
* 3가지 핵심 구성 요소

---

## 39. 데이터 사이언티스트가 갖춰야 할 역량(가트너)
1. 데이터 관리: 데이터에 대해 이해
2. 분석 모델링: 분석론에 대한 지식
3. 비즈니스 분석: 비즈니스 요소에 초점
4. 소프트 기능: 커뮤니케이션, 협력, 리더십, 창의력</br>

%데이터 사이언티스트가 갖춰야 할 역량의 공통점은 호기심, 호기심이란 문제의 이면을 파고들고, 질문들을 찾고, 검증 가능한 가설을 세우는 능력 또한 스토리텔링, 커뮤니케이션, 직관력, 소통 능력 필요

### 출제 유형
* 결국 데이터 사이언티스트는 정량분석이라는 과학과 인문학적 통찰에 근거한 합리적 추론을 조합한다.

---

## 40. 데이터 사이언티스트 요구역량(하드스킬 & 소프트 스킬)
1. Hard Skill
* 빅데이터에 대한 이론적 지식: 관련 기법에 대한 이해와 방법론 습득
* 분석 기술에 대한 숙련: 최적의 분석 설계 및 노하우 축적
2. Soft Skill
* 통찰력 있는 분석: 창의적 사고, 호기심, 논리적 비판
* 설득력 있는 전달: 스토리텔링, Visualization
* 다분야 간 협력 : Communication

### 출제 유형
* 하드스킬과 소프트스킬 개념 및 구분

---

## 41. 인문학의 부활 이유
1. 단순 세계화에서 복잡한 세계로의 변화
2. 비즈니스의 중심이 제품생산에서 서비스로 이동
3. 경제와 산업의 논리가 생산에서 시장 창조

---

## 42. 데이터 사이언티스트 6가지 핵심 질문
|     | 과거 | 현재 | 미래 |
|-----|-----|-----|-----|
| 정보 | 무슨일이 일어났는가? </br> ex)리포팅(보고서) | 무슨일이 일어나고 있는가? </br> ex)경고 | 무슨 일이 일어날 것인가? </br> ex) 추출 |
| 통찰 | 어떻게, 왜 일어났는가? </br> ex) 모델링, 실험설계 | 차선 행동은 무엇인가? </br> ex) 권고 | 최악, 최선의 상황은? </br> ex) 예측, 최적화 시뮬레이션 |

### 출제 유형
* 정보와 통찰 사례

---

## 43. 가치 패러디임의 변화
1. 디지털화(Digitalizaiton): 아날로그의 세상을 어떻게 효과적으로 디지털화하는가가 이 시대의 가치를 창출해 내는 원천
2. 연결(Connection): 디지털화된 정보와 대상들이 서로 연결되어, 이 연결이 얼마나 효과적이고 효율적으로 제공해 주느냐가 이 시대의 성패를 결정함
3. 에이전시(Agency): 사물인터넷(Iot)의 성숙과 함께 연결이 증가하고 복잡한 연결을 얼마나 효과적이고 믿을 만하게 관리하는가가 이슈. 데이터 사이언스의 역량에 따라 좌우

### 출제 유형
* 가치 패러다임의 변화 순서

---

## 44. 자주 출제되는 기타 용어정리
1. 데이터 레이크(Data Lake):대규모의 다양한 원시 데이터셋을 기본형식으로 저장하는 데이터 리포지토리 유형. 데이터 레이크에 있는 데이터는 분석을 위해 필요할 때 변환되며, 이러한 경우 스키마가 적용되어 데이터 분석이 가능해집니다.
이는 '읽기 스키마(Schema on read)'라고 불리고, 데이터가 사용 준비 상태가 될때까지 원시 상태로 보관되기 때문
2. 서비타이제이션(Servitization): 제품과 서비스의 결합, 서비스의 상품과 그리고 기존 서비스의 신규 버시스의 결합 협상을 포괄하는 개념
3. 딥러닝(Deep Learning): 여러 층을 가진 인공신경망(ArtificialNeural Network)을 사용하고 머신러닝 학습을 수행하는 것으로 심층학습 기법으로 대표적 분석방법으로 LSTM, Autoencoder, RNN 등이 있음
4. 마이데이터: 개인이 각족 기업과, 기관에 흩어져 있는 자신의 신용 정보를 마이데이터 사업자에게 활용하도록 하고, 이들 업체로부터 자신에게 유용한 맞춤형 서비스를 받는 것을 의미함

---

## 45. SQL
* SQL(Structure Query Language)은 관계 데이터베이스를 위한 표준 질의어를 의미한다.
SQL는 기능에 따라 데이터 정의어(DDL), 데이터 조작어(DML), 데이터 제어어(DCL)로 나눈다.

1. 데이터 정의의(DDL)
* 스키마, 테이블, 뷰 등을 정의하거나 변경, 삭제할 때 사용하는 언어
* 데이터베이스 관리자 혹은 설계자가 사용함
* 유형 : CREATE / ALTER/ DROP

2. 데이터 조작어(DML)
* 데이터베이스 사용자가 저장된 데이터를 처리할 때 사용하는 언어
* 데이터베이스 사용자가 관리시스템 간의 인터페이스를 제공함
* 유형: SELECT / INSERT / DELETE / UPDATE

3. 데이터 제어어(DCL)
* 데이터의 보안, 무결성 등을 정의하는데 사용되는 언어
* 데이터베이스 관리자가 데이터 관리를 목적으로 사용함
* 유형 : COMMIT / ROLLBACK / GRANT / REVOKE

### 출제 유형
* 데이터 정의어, 데이터 조작어, 데이터 제어어 유형 구분

---

## 46. ETL(Extraction, Transformation and Load)
* ETL은 데이터 이동과 변환 절차와 관련된 업계표준용어이다.
* ETL은 데이터웨어하우스(DW), 운영 데이터 스토어(ODS), 데이터 마트(DM)에 대한 데이터 적재 작업의 핵심 구성요소이다.
* 데이터 통합(Data Integration), 데이터 이동(Data Migration), 마스터 데이터 관리(MDM, Master Data Management)에 걸쳐 폭넓게 활용된다.
* ETL은 데이터 이동과 변환을 주목적으로 하며 3가지 기능으로 구성된다.
1. Extraction(추출) : 하나 또는 그 이상의 데이터 원천들로부터 데이터 획득
2. Transformation(변형) : 데이터 클렌징, 형식 변환, 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용
3. Loading(적재): 위 변형 단계 처리가 완료된 데이털르 특정 목표 시스템에 적재

### 출제 유형
* ETL의 정의 및 기능

---

## 47. 하둡의 구성요소
* 하둡은 하나의 성능 좋은 컴퓨털르 이용하여 데이터를 처리하는 대신, 적당한 성능의 범용 컴퓨터 여러 대를 클러스터화하고, 큰 크기의 데이터를 클러스터에서 병렬로 동시에 처리하여 처리 속도를 높이는 것을 목적으로 한다.
* 하둡의 코어 프로젝트가 HDFS와 MapReduce이며 이외에도 다양한 서브프로젝트가 존재한다. 이러한 서브프로젝트들의 모임을 하둡의 에코시스템이라 한다

1. HDFS(Hadoop Distributed File System): 네트워크에 연결된 기기에 데이털르 저장하는 분산형 파일 시스템이다.
2. MapReduce: 대용량 데이터 처리를 위한 분산 프로그래밍 모델로, 대규모 분산 컴퓨팅 환경에서 대량의 데이터를 병렬로 분석한다.

### 출제 유형
* 하둡의 구성요소인 HDFS와 MapReduce의 정의

---


# 2과목. 데이터의 분석 기획

## 48. 분석 주제 유형
* 분석의 대상(What) 및 분석의 방법(how)에 따라 4가지 유형으로 구분
1. Optimization : 분석 대상 및 분석 방법을 이해하고 현 문제를 최적화의 형태로 수행
2. Solution : 분석 과젠느 수행되고, 분석 방법을 알지 못할 경우 솔루션을 찾는 방식으로 분석 과제수행
3. Insight: 분석 대상이 불분명하고, 분석 방법을 알고 있는 경우 인사이트 도출
4. Discovery: 분석 대상, 방법을 모른다면 발견을 통하여 분석 대상 자체를 새롭게 도출
* 분석의 주제 및 기법의 특성상 이러한 4가지 유형은 서로 융합적으로 반복하게 됨

### 출제 유형
* 4가지 주제 유형 정의

---

## 49. 목표 시점별 기획 방안
* 과제 중심적인 접근 방식: 당면한 과제를 빠르게 해결
* 장기적인 마스터플랜 방식: 지속적인 분석 내재화로 해결

| 당면한 분석 주제 해결 |        | 지속적 분석문화 내재화 |
|------------------|--------|------------------|
| 과제 단위 |        | 마스터플랜 단위 |
| Speed & Test | <1차 목표> | Accuracy & Deploy |
| Quick - Win | <과제의 유형> | Long Term View |
| Problem Solving | <접근 방식> | Problem Definition |

### 출제 유형
* 과제단위와 마스터플랜 단위 구분 문제 출제

---

## 50. 분석기획 시 고려사항
1. 가용한 데이터(Available Data)</br>
데이터 유형에 따라서 적용 가능한 솔루션 및 분석 방법이 달라서 유형에 대한 분석이 선행적으로 이루어져야 함
2. 적절한 유스케이스(Proper Use-Case)탐색</br>
유사 분석 시나리오 및 솔루션이 있다면 이를 최대한 활요하는 것이 중요함
3. 장애요소들에 대한 사전 계획 쉷이 필요함

### 출제 유형
* 분석기획 시 고려사항

---

## 51. 데이터 저장 방식

| 저장 방식 |        특징        | 도구 |
|---------|-------------------|-----|
| RDB | * 관계형 데이터를 저장하거나 수정하고 관리할 수 있게 해주는 데이터베이스<br> * SQL문장을 통하여 데이터베이스의 생성, 수정 및 검색 등 서비스를 제공 | Oracle, MSSQL, MySQL 등 |
| NoSQL | * NoSQL 데이터베이스 = 비관계형(비정형) 데이터베이스 관리 시스템 <br> * NoSQL은 빅데이터 분산처리 및 저장기술과 함께 발달한 분산 데이터베이스 기술로 확장성 및 가용성을 제공 <br> * 대용량 처리와 대규모의 수평적 확장성 제공한다. | MongoDB, Cassandra, HBase, Redis |
| HDFS | * HDFS와 기존의 대용량 파일시스템의 큰 차이점은 HDFS는 저사양 서버를 이용해 스토리지를 구성함 <br> * 기존의 대용량 파일시스템 또는 데이터베이스를 구성하려면 고성능의 서버나 대용량의 외장 스토리지가 필요하였으며 이러한 시스템은 웹 서버와 같은 서버에 비해 상당히 많은 비용이 발생하게 된다. 하지만 HDFS를 이용하면 수십 혹은 수백 대의 웹 서버급 서버나 저사양 서버를 묶어서 하나의 스토리지 처럼 사용 할 수 있게 됨| HDFS등 |

### 출제 유형
* NoSQL 과 RDBMS 저장 도구 종류 구분

---

## 52. 기업의 합리적 의사결정 장애 요소
1. 고정관념(Stereotype)
2. 편향된 생각(Bias)
3. 프레이밍 효과(Framing Effect): 문제의 표현 방식에 따라 같은 사건이나 상황임에도 불구하고 개인의 판단 이나 선택이 달라질 수 있는 현상
* 데이터 기반의 의사결정을 위해서는 기업문화의 변화와 업무 프로세스 개선이 필요

### 출제 유형
* 기업의 합리적 의사결정 장애요소 3가지 정의

---

## 53. 분석 방법론의 구성 요소
1. 상세한 절차(Procedure)
2. 방법(Methods)
3. 도구와 기법(Tools & Techniques)
4. 템플릿과 산출물(Templates & Outputs)로 구성

### 출제 유형
* 분석방법론의 구성요소

---

## 54. 폭포수 vs 나선형 vs 프로토타입 모델
1. 폭포수 (waterfall)모델
* 단계별로 철저한 검토와 승인 과정을 거쳐 확실히 매듭짓고 다음 단계로 진행하는 모델
* 하향식(Top Down) 진행되지만, 문제나 개선사항이 발견되면 전 단계로 돌아가는 피드백 과정 수행
2. 나선형(Spiral)모델
* 여러 번의 개발 과정을 거쳐 점진적으로 프로젝틀르 완성해가는 모델
* 처음 시도하는 프로젝트에 적용이 용이, 반복에 대한 관리체계를 효과적으로 갖추지 못한 경우 프로젝트 진행이 어려움
* 대규모 시스템 소프트웨어 개발에 적합
3. 프로토타입(Prototype)모델
* 사용자가 요구사항이나 데이터를 정확히 규정하기 어렵고 데이터 소스도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해 보고 그 결과를 확인해가면서 반복적으로 개선해 나가는 방법
* 프로토타이핑 모델은 요구사항을 분석한 후 프로토타입을 개발하여, 평가를 받는다. 평가 결과에 따라 개발 샐행 또는 프로토타입 개선이나 요구사항을 재분석한다.
폭포수 모델의 피드백에 대한 어려움을 보완하기 위해 프로토타이핑 제작과 평가를 추가함

### 출제 유형
* 각 모델의 장단점과 모델의 차이점

---

## 55 KDD 분석 방법론
* KDD(Knowledge Discovery in Database)는 1996년 Fayyad가 체계적으로 정리한 데이터 마이닝 프로세스로서 데이터베이스에서 의미있는 지식을 탐색하는 데이터 마이닝,
기계학습, 인공지능, 패턴인식, 데이터 시각화 등에서 응요될 수 있는 구조를 갖추고 있다.

---

## 56. KDD 분석 절차
1. 분석 대상의 비즈니스 도메인에 대한 이해와 프로젝트 목푤르 정확하게 설정
2. 데이터 세트 선택(Selection)
3. 데이터 전처리(Preprocessing): 분석 데이터 세트에 포함된 잡음(Noise), 이상값(Outlier), 결측치(Missing value)를 식별하고 필요할 때 제거한다.
4. 데이터 변환(Transformation): 분석 목적에 맞는 변수를 선택하거나 데이터의 차원을 축소하여 데이터 마이닝을 효율적으로 적용할 수 있도록 데이터셋을 변경한다.
5. 데이터 마이닝(Data Mining): 변환된 데이터 세트를 이용하여 분석 목적에 맞는 데이터 마이닝기법을 선택하고, 데이터 마이닝 알고리즘을 선택하여 데이터의 패턴을 찾거나 데이터를 분류 또는 예측하는 등의 마이닝 작업을 시행한다.
6. 데이터 마이닝 결과 평가(Interpretation / Evaluation): 분석 결과에 대한 해석과 평가 그리고 활용을 한다.

### 출제 유형
* KDD 분석 단계별 내용과 순서

---

## 57. CRISP-DM 분석 방법론
* CRISP-DM(Cross Industry Standard Process For Data Mining)프로세스는 6단계로 구성되어 있으며,
각 단계는 폭포수 모델처럼 한 방향으로 구성되어 있지 않고 단계 간 피드백을 통하여 완성도를 높이게 됨


<img src="/assets/images/ADSP_빅데이터분석기사_posts//CRISP-DM.jpeg", height="100x", width="100px">


![poster](/assets/images/ADSP_빅데이터분석기사_posts//CRISP-DM.jpeg)

### 출제 유형
* 화살표의 양방향(피드백)이 형성되는 구간

## 58. CRISP-DM 분석 절차
1. 업무 이해(Business Understanding)<br>
* 비즈니스 관점 프로젝트의 목적과 요구사항을 이해하기 위한 단계
* 도메인 지식을 데이터 분석을 위한 문제 정의로 변경하고 초기 프로젝트 계획을 수립하는 단계
* 업무 목적 파악, 상황 파악, 데이터 마이닝 목표설정, 프로젝트 계획 수립으로 구성
2. 데이터 이해(Data Understanding)
* 데이터 이해는 분석을 위한 데이터를 수집하고 데이터 속성을 이해하기 위한 과정으로 구성되고, 데이터 품질에 대한 문제점을 식별하고 숨겨져 있느 인사이트를 발견하는 단계
* 초기 데이터 수집, 데이터 기술 분석, 데이터 탐색, 데이터 품질 확인
3. 데이터 준비(Data Preparation)
* 데이터 준비는 분석을 위하여 수집된 데이터에서 분석기법에 적합한 데이터 세트를 편성하는 단계로 많은 시간이 소요될 수 있음
* 분석용 데이터 세트 선택, 데이터 정체, 데이터 통합, 데이터 포맷팅이 해당
4. 모델링(Modeling)
* 다양한 모델링 기법과 알고리즘을 선택하고 모델링 과정에서 사용되는 파라미터를 최적화해 나가는 단계
* 이 단계를 통해 찾아낸 모델은 테스트용 프로세스와 데이터셋을 평가하여 모델 과적합(Overfitting) 등의 문제를 발견하고 대응방안을 마련함
* 모델링 기법 선택, 모델 테스트 계획 설계, 모델 작성, 모델 평가로 구성
5. 평가(Evaluation)<br>
프로젝트의 목적에 부합하는지 모델 평가
* 데이터 마이닝 결과 수용 여부를 최종적으로 판단
* 분석 결과평가, 모델링 과정 평가, 모델 적용성 평가

6. 전개(Deployment)
* 모델링과 평가 단계를 통하여 완성된 모델을 실제 업무에 적용하기 위한 계획을 수립하고 모니터링과 모델의 유지보수 계획 마련
* 전개 계획 수립, 모니터링과 유지보수 계획 수립, 프로젝트 종료 보고서 작성, 프로젝트 검토로 구성

### 출제 유형
* CRISP-DM 분석 단계별 내용 구분

---

## 59. 빅데이터 분석 방법론 계층적 프로세스 모델 : 3계층으로 구성

![모델3계층](/assets/images/ADSP_빅데이터분석기사_posts//모델3계층.jpeg)

#### 용어 정리
- WBS는 무엇인가? Project Management에 이용되는 기법의 하나로 Project 전체를 작은 작업 단위로 분할한 구성도, 사전적인 의미로는 Project의 범위와 최종 산출물을 세부요소로 분할한 계층적 구조도라고 정의함

### 출제 유형
* 빅데이터 계층적 구성 구분

## 60. 빅데이터 분석 방법론

![빅데이터 분석 방법론](/assets/images/ADSP_빅데이터분석기사_posts//빅데이터_분석_방법론.jpeg)

* 분석 단계를 수행하는 과정에서 추가적인 데이터 확보가 필요한 경우 데이터 준비단계로 피드백 가능
* 데이터 분석 단계에서 프로토타입 시스템을 구현하고자 하는 경우 시스템 구현 단계를 수행한다.

### 출제 유형
* 빅데이터 분석 방법론 단계 - 태스크 - 스탭으로 구분하고 순서와 해당 단계의 태스크까지 알고 있어야 함

---

## 61. 분석 기획(planning) : phase 해당
1. 비즈니스 이해 범위설정 : task 해당
* 비즈니스 이해 : 내부 업무 메뉴얼과 관련 자료, 외부의 관련 비즈니스 자료 조사 향후 프로젝트 방향 설정
* 프로젝트 범위 설정 : 비즈니스 이해와 프로젝트 목적에 부합되는 범위설정 : step 해당
* SOW : project manager 프로젝트 수행 전에 개념정리 기회제공, 프로젝트 팀원들에게 한눈에 프로젝트 전체를 볼 수 있게 하고, 진행 도중 새롭게 투입된 팀원에게 전달하기 위해 작성
2. 프로젝트 정의 및 계획 수립 -> task
3. 프로젝트 위험계획 수립
* 계획 수립 단계에서 빅데이터 분석 프로젝트를 진행하면서 발생 가능한 모든 위험(Risk)을 발굴하여 사전에 대응방안 수립
* 위험 대응 계획 수립 예상되는 위험에 대한 대응은 회피(avoid), 전이(transfer), 완화(mitigate), 수용(accept)구분하여 관리 계획서를 작성
* 리스크는 제거하는 것이 아니라 일정 수준 이하로 낮추는 것

#### 용어 정리
* 회피(Avoidance): 발생원인 제거하는 것
* 전가(Transfer): 제3자에게 이전, 보험, 보증
* 완화(Mitigation): 용인 가능한 임계치까지 관리
* 수용(Acceptance): 실제 발생 시 대응, 리스크가 발생하기 전에 어떤 조치도 취하지 않는 것

---

## 62. 데이터 준비
1. 필요데이터 정의
2. 데이터 스토어 설계
* 정형 데이터 스토어 설계
* 비정형 데이터 스토어 설계
3. 데이터 수집 및 정합성 점검

---

## 63. 데이터 분석
1. 분석용 데이터 준비
2. 텍스트 분석
3. 탐색적 분석: 다양한 데이터 시각화를 활요하여 데이터의 가독성을 명확히 하고 데이터의 형상 및 분포 등 데이터 특성파악

---

## 64. 모델링
모델링이란 분석용 데이터를 이용한 가설 설정을 통해 통계 모델을 만들거나 기계학습을 이용한 데이터 분류, 예측, 군집 등의 기능을 수행하는 모델을 만드는 과정을 말한다.
* 데이터 분할: 모델의 과적합과 일반화를 위해 분석용 데이터셋을 모델 개발을 위한 훈련용 데이터와 모델의 검증력을 테스트하기 위한 데이터로 나눈다.
* 데이터 모델링: 기계학습 등을 잉요한 데이터 모델링은 훈련용 데이터를 활용하여 분류 또는 예측, 군집 등의 모델을 만들어 가동중인 운영 시스템에 적용한다. 또한 필요시 비정형 데이터 분석 결과를 통합적으로 활용하여 프로젝트 목적에 맞는 통합 모델링을 수행한다.<br>
(처리 및 도구) - 통계 모델링 기법, 기계학습<br>
(출력 자료) - 모델링 결과 보고서<br>
* 모델 적용 및 운영 방안: 모델에 대한 상세한 알고리즘 설명서 작성이 필요하다. 알고리즘 설명서는 시스템 구현 단계에서 중요한 입력자료로 활용되므로 필요시 의사코드 수준의 상세한 작성이 필요할 수 있다.

#### 용어 정리
* 의사 코드: 일반적인 언어로 코드를 흉내 내어 알고리즘을 써놓은 코드, 특정 언어로 프로그램을 작성하기 전에 알고리즘의 모델을 대략적으로 모델링할 때 사용

### 출제 유형
* 모델링 저으이 , 데이터 분할의 목적

---

## 65. 모델 평가 및 검증
* 모델 평가: 모델 평가를 위해서는 모델 결과 보고서 내의 알고리즘을 파악하고 테스트용 데이터나 필요시 모델 검증을 위한 별도의 데이터를 활용할 수 있다.
* 모델 검증: 검증용 데이터는 모델 개발 및 평가에 활용된 훈련용 데이터나 테스트용 데이터가 아닌 실세 운영용 데이터를 확보하여 모델의 품질을 최종 검증하는 프로세스

### 출제 유형
* 모델링의 태스크과 비교

---

## 66. 시스템 구현
분석 기획의 의도에 맞는 모델을 데이터 분석 단계를 진행하여 도출하고 이를 우녕ㅇ중인 시스템에 적용하거나 프로토타입을 구현하고자 하는 경우 시스템 구현 단계를 진행한다. 단순한 데이터 분석이나 데이터 마이닝을 통한
분석 보고서를 작성하는 것으로 프로젝트가 종료되는 경우에는 시스템 구현 단계를 수행할 필요가 없고 다음 단계인 평가 및 전개 단계를 수행한다.
1. 설계 및 구현
* 시스템 분석 및 설계
* 시스템 구현
2. 시스템 테스트 및 운영
* 시스템 테스트
* 시스템 운영 계획

---

## 67. 평가 및 전개
1. 모델 발전 계획 쉷
* 모델 발전 계획 수립
2. 프로젝트 평가 및 보고
* 프로젝트 성과 평가
* 프로젝트 종료(프로젝트 최종 보고서 작성)

---

## 68. 분석 과제 발굴
* 문제가 주어져 있는 상태에서 답을 구하는 하향식 접근 방식이 전통적으로 수행되었던 분석 과제 발굴이다.
* 대규모의 다양한 데이터를 생성하고 빠르게 변화는 기업 환경에서는 문제 자체의 변화가 심해 문제를 사전에 정의하는 것이 어려워지고 있다.
데이터를 활요하여 생각하지 못했던 인사이트를 도출하고 시행착오를 통해서 개선해 가는 상향식 접근 방식이 점차 증가하고 있는 추세이다.

### 출제 유형
* 상향식 접근방식과 하양식 접근방식 차이점

---

69. 디자인 씽킹
* 디자인 씽킹이란 넓은 의미에서 디자이너의 사고 방식을 의미, 간단하게 말하자면 '디자이너처럼 생각하자'
디자이너는 시작 단계에서 대상을 자세히 관찰하고 그 상황이나 대상에 공감함으로써 많은 가능성과 이이디어를 생각한다.
* 그 이후 많은 아이디어를 내고 그것을 다시 필터링하고 이 과정을 반복함으로써 최선의 결과를 얻는다.
* 디자인 씽킹은 사용자들에게 공감하는 그것에서 시작해 아이디어를 발산하고 곧 수렴하는 과정을 거쳐 많은 프로토타이핑과 피드백에 의해 발전하는 과정이다.

![디자인 씽킹](/assets/images/ADSP_빅데이터분석기사_posts//디자인_씽킹.jpeg)

### 출제 유형
* 다지안 씽킹의 개념과 상향식(발산)과 하양식(수렴)이 출제

---

## 70. 디자인 씽킹 프로세스 5단계
1. Empathize: 사용자 인터뷰 등을 통해 고객의 문제에 공감하는 단계
2. Define: 첫 번째 얻는 통찰을 바탕으로 고객의 문제를 정의하느 과정 ex) pain point 발굴
3. Ideate: 현실 가능성을 고려하지 않고 자유롭게 고객에게 적합한 해결 방안을 제시 ex) pain point 개선 중심
4. Prototype: 새로운 아이디어를 프로토타입으로 만들어 보거나 서비스에 대한 시나리오를 만들어 보는 단계
5. Test: 일차적으로 완성된 프로토타입에 대한 고객의 피드백을 바탕으로 프로토타입을 개선해 보는 단계

### 출제 유형
* 디자인 씽킹 프로세스 단계별 개념 정리 및 순서

---

## 71. 하향식 접근법(Top - Down)

![하향식 접근 방법](/assets/images/ADSP_빅데이터분석기사_posts//하향식_접근_방법.jpeg)

하향식 접근법의 한계
* 문제의 구조가 분명하고 문제를 해결하고 해결책 시도에는 적합, 새로운 문제의 탐색에 한계가 있음

### 출제 유형
* 하향식 접근 방식의 프로세스 순서

---

## 72. 문제 탐색(Problem Discovery)
전체적인 관점의 기준 모델을 활용하여 빠짐없이 문제를 도출하고 식별하는 것이 중요하다.
1. 비즈니스 모델 기반 탐색
* 업무(Operation)
* 제품(Product)
* 고객(customer)
* 규제와 감사(Regulation & audit)
* 지원 인프라(IT & Human Resource)

### 출제 유형
* 비즈니스 모델 기반 문제 탐색 5개 영역

---

## 73. 혁신의 관점(중장기관점) 분석 기회 발굴 확장
1. 거시적 관점(STEEP)
* 사회(Social)영역
* 기술(Technology)영역
* 경제(Economic)영역
* 환경(Environmental)영역
* 정치(Political)영역
2. 경쟁자 확대 관점(위협이 될 수 있는 상황)
* 대체재 영역 : 현재 생산을 수행하고 있는 제품, 서비스의 주요 경쟁자에 대한 동향 파악
* 신규진입자 영역 : 향후 시장에 대해서 위협이 될 수 있는 신규진입자 동향 파악
3. 시장의 니즈 관점
* 고객 영역: 고객의 구매 동향 및 고객의 컨텍스트를 더욱 깊게 이해하여 제품-서비스의 개선 필요에 필요한 분석 기회 도출
* 채널 영역: 영업 사원, 직관 대리점, 홈페이지 등의 자체적으로 운영하는 채널 뿐만 아니라 최종 고객에게 상품-서비스를 전달하는 것에 경로로 존재하는 가능한 경로를 파악하여 해당 경로에 존재하는 채널별로 분석 기회를 확대하여 탐색
* 영향자들 영역: 기업 의사결정에 영향을 미치는 주주-투자자-협회 및 기타 이해관계자의 주요 관심사항에 대해서 파악하고 분석기회 탐색

4. 역량의 재해석 관점
* 내부 역량 영역: 지식, 기술 등의 노하우와 유형자산의 노하우
* 파트너와 네트워크 영역: 자사가 보유하고 있지 않지만, 관계를 유지하고 있는 관계사 역량 활용 파악

### 출제 유형
* 혁신적 관점은 분석기회 발굴의 확장으로 경쟁자 확대관점, 시장의 니즈관점, 역량의 재해석 관점의 영역별 개념

---

## 74. 외부 참조 모델 기반 탐색
* 유사 - 동종의 환경에서 기존에 수행한 분석 과제를 살펴보는 것도 주요한 시사점 도출
* 평상시 지속적인 조사와 데이터 분석을 통한 가치 발굴 사례를 정리하여 풀(Pool)로 만들어 둔다면 과제 발굴 및 탐색 시 빠르고 의미 있는 분석 기회 도출 가능

#### 용어 정리
- 분석 유즈 케이스: 분석 유즈 케이스는 풀어야 할 문제에 대한 상세한 설명 및 해당 문제를 해결했을 때 발생하는 효과를 명시함으로 데이터 분석 문제로의 전환 및 적합성 평가에 활용

### 출제 유형
* 분석 유즈 케이스 단답형 문제로 출제

---

## 75. 문제 정의(Problem Definition)
식별된 비즈니스 문제를 데이터 문제로 변환하여 정의하는 단계. 앞서 수행한 문제탐색의 단계가 무엇을 어떤 목적으로 수행해야 하는지에 대한 관점이라면 이 단계에서는 필요한 데이터 및 기법을 정의하기 위한 데이터 분석 문제로의 변환을 수행하게 된다.

### 출제 유형
* 개념 정의

---

## 76. 해결방안 탐색
동일한 데이터 분석 문제라 해도 어떤 데이터 또는 분석 시스템을 사용할 것인지에 따라서 소요되는 예산 및 활용 가능한 도구가 다르므로 여러모로 고려한다.


---

## 77. 타당성 검토 단계
* 도출된 분석 문제나 가설에 대한 대안을 과제화하기 위해서는 다각적인 타당성 분석이 수행
1. 경제적 타당성: 비용대비 편익 분석 관점의 접근
2. 데이터 타당성 : 데이터 존재여부
3. 기술적 타당성 : 기술적 분석역량 확보
-> 도출된 대안 중에서 가장 우월한 대안을 선택 분석 과제 정의서 형태로 시행 후 프로젝트 계획의 입력자료로 활용

### 출제 유형
* 타당성 검토의 종류 및 개념

---

## 78. 상향식 접근 방식(Bottom Up Approach)
* 문제의 정의 자체가 어려운 경우 데이터를 기반으로 문제의 재정의 및 해결 방안을 탐색하고 이를 지속해서 개선하는 방식이며, 일반적으로 상향식 접근 방식의 데이터 분석은 비지도 학습(Unsupervised Learning) 방법에 따라 수행된다.
* 통계적 분석에서는 인과관계(원인과 결과) 분석을 위홰 가설을 설정하고 이를 검정하기 위해 모집단으로 표본을추출하고, 그 표본을 이용한 가설검정을 하는 방식으로 문제를 해결한다.
* 그러나 빅데이터 환경에서는 이와 같은 논리적인 인과 관계 분석뿐만 아니라 상관관계 분석 또는 연관분석을 통하여 다양한 문제해결에 도움을 받을 수 있다. 즉 인과관계로부터 상관관계 분석으로의 이동이 빅데이터 분석에서의 주요 변화라고 할 수 있다.
* 다량의 데이터 분석을 통해서 "왜" 그러한 일이 발생하는지 역으로 추적하면서 문제를 도출하거나 재정의할 수 있는 것이 상향식 접근 방법이다.

#### 용어 정리
- 애자일 모델: 전체적인 플랜을 짜고 문서를 주도해나가던 과거의 방식(워터폴 모델)과 달리 앞을 예측하며 개발하지 않고, 일정한 주기를 가지고 끊임없이 프로토타입을 만들어내며 필요할 때마다 요구사항을 더하고 수정하여 커다란 소프트웨어를 개발해 나가는 방식

### 출제 유형
* 상향식 접근 방식의 개념

---

## 79. 프로토타이핑 프로세스
* 프로토타이핑 접근법은 사용자가 요구사항이나 데이터를 정확히 규정하기 어렵고 데이터 소스도 명확히 파악하기 어려운 상황에서 일단 분석을 시도해보고 그 결괄르 확인해가면서 반복적으로 개선해나가는 방법
* 하향식 접근법은 문제가 정형화되어 있고, 문제해결을 위한 데이터가 완벽하게 존재할 경우 효과적이다.
* 프로토타이핑은 방법론 비록 완전하지는 못하다 해도 신속하게 해결책이나 모형을 제시함으로써 문제를 좀 더 명확하게 인식하고 필요한 데이터를 식별하여 구체화하게 하는 상향식 접근 방식이다.<br>
->프로토타이핑 접근법은 결국 빅데이터 분석 환경에서 유용

### 출제 유형
* 프로토타이핑 개념

---

## 80. 빅데이터 환경에서 프로토타이핑 역활
1. 문제에 대한 인식 수준
* 문제 정의가 불명확하거나 이전에 접해보지 못한 새로운 문제인 경우 사용자 또는 이해관계자는 프로토타입을 이용하여 문제를 이해하고 이를 바탕으로 구체화하는 데 도움을 받을 수 있다.
2. 필요데이터 존재 여부의 불확실성
* 대체 불가능한 데이터를 사전에 확인한다면 불가능한 프로젝트를 수행하는 리스크를 사전에 방지할 수 있다.
3. 데이터 사용 목적의 가변성


### 출제 유형
* 빅데이터 환경에서 프로토타이핑 3가지 역활

---

## 81. 분석 관제 정의서
* 다양한 방식을 통해서 도출한 분석 과제를 분석 과정의서 양식으로 정의한다.
* 분석 과제 정의서는 향후 프로젝트 수행 계획의 입력물로 사용되기 때문에 프로젝트 수행하는 이해관계자가 프로젝트 방향을 설정하고 성공 여부를 판별할 수 있는 주요한 자료로서 상세하게 작성되어야 한다.

### 출제 유형
* 분석 과제 저의서의 작성 주요 항목

---

## 82. 분석 프로젝트 관리방안
* 과제 형태로 도출된 분석 기회는 프로젝트를 통해서 그 가치를 증명하고 목표를 달성해야 한다.
* 분석 프로젝트는 다른 프로젝트 유형처럼 범위, 일정, 품질, 리스크, 의사소통 등 영역별 관리가 수행되어야 할 뿐 아니라 다양한 데이터에 기반한 분석기법을 적용하기 때문에 5가지 주요 속성을 고려하여 추가적인 관리가 필요
1. Data Size
2. DAta Complexity
* BI 프로젝트처럼 정형 데이터가 분석 마트로 구성되어 있는 상태에서 분석하는 것과 달리 비정형, 반정형 데이터가 존재할 경우 데이터 확보뿐만 아니라 분석모델의 선정 등에 대한 사전 고려가 필요
3. Speed
4. Analytic Complexity
* 분석 모델의 정확도와 복잡도. 분석 모델이 복잡할수록 정확도는 올라가지만, 해석이 어려워지는 단점이 존재하므로 이에 관한 기준점을사전에 정의해야 한다.
5. Accuracy & Precision
* Accuracy는 모델과 실제 값 차이가 적다는 정확도를 의미하고 Precision은 모델을 지속적을 ㅗ반복했을 때 편차의 수준으로써 일관적으로 동일한 결과 제시한다는 것을 의미
* 분석의 활용측면에서는 Accuracy가 중요, 안전성 측면에서는 Precision이 중요하다.
* 이 둘의 관계는 트레이드 오프 관계로 모델의 해석 및 적용 시 사전에 고려해야 한다.
-> 분석 프로젝트는 도출된 결과의 재해석을 통한 지속적인 반복 및 정교화가 수행된느 경우가 대부분이므로 프로토타이핑 방식의 애자일(Agile) 프로젝트 관리방식에 대한 고려도 필요

### 출제 유형
* 분석프로젝트 5가지 속성

---

## 83. 분석 프로젝트 영역별 주요 관리 항목
1. 범위(Scope)
2. 시간(Time)
* 데이터 분석 프로젝트는 초기에 의도했던 결과가 나오기 쉽지 않기 때문에 시간이 소요될 수 있음
* 그래서 품질을 보장한다는 전제하에 타임방식 기법으로 일정관리를 진행한다.(철저한 통제가 아니다.)
3. 원가(Cost)
4. 품질(Quality)
* 프로젝트 품질은 QC와 QA로 나누어 수행
